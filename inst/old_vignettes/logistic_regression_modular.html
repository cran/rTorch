<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Alfonso R. Reyes" />

<meta name="date" content="2018-01-22" />

<title>Logistic Regression - rTorch</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Logistic Regression - rTorch</h1>
<h4 class="author"><em>Alfonso R. Reyes</em></h4>
<h4 class="date"><em>2018-01-22</em></h4>



<div id="import-libraries" class="section level2">
<h2>Import libraries</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rTorch)

Variable   &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;torch.autograd&quot;</span>)<span class="op">$</span>Variable
np         &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;numpy&quot;</span>)
optim      &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;torch.optim&quot;</span>) 
py         &lt;-<span class="st"> </span><span class="kw">import_builtins</span>()</code></pre></div>
</div>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># reproducible</span>
torch<span class="op">$</span><span class="kw">manual_seed</span>(42L)
<span class="co">#&gt; &lt;torch._C.Generator&gt;</span>

<span class="co"># load or download MNIST dataset</span>
mnist &lt;-<span class="st"> </span><span class="kw">dataset_mnist</span>(<span class="dt">onehot =</span> <span class="ot">FALSE</span>)

trX   &lt;-<span class="st"> </span>mnist[[<span class="dv">1</span>]]; teX =<span class="st"> </span>mnist[[<span class="dv">2</span>]]; trY =<span class="st"> </span>mnist[[<span class="dv">3</span>]]; teY =<span class="st"> </span>mnist[[<span class="dv">4</span>]]

trX &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(trX)<span class="op">$</span><span class="kw">float</span>()      <span class="co"># FloatTensor</span>
teX &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(teX)<span class="op">$</span><span class="kw">float</span>()      <span class="co"># FloatTensor</span>
trY &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(trY)<span class="op">$</span><span class="kw">long</span>()       <span class="co"># LongTensor</span>
teY &lt;-<span class="st"> </span>torch<span class="op">$</span><span class="kw">from_numpy</span>(teY)<span class="op">$</span><span class="kw">long</span>()       <span class="co"># LongTensor</span></code></pre></div>
</div>
<div id="model-parameters" class="section level2">
<h2>Model parameters</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># in Python was: n_examples, n_features = trX.size()</span>
<span class="co"># using new R function torch_size()</span>
n_examples    &lt;-<span class="st"> </span><span class="kw">torch_size</span>(trX<span class="op">$</span><span class="kw">size</span>())[<span class="dv">1</span>]
n_features    &lt;-<span class="st"> </span><span class="kw">torch_size</span>(trX<span class="op">$</span><span class="kw">size</span>())[<span class="dv">2</span>]

learning_rate &lt;-<span class="st"> </span><span class="fl">0.01</span>
momentum      &lt;-<span class="st"> </span><span class="fl">0.9</span>
n_classes     &lt;-<span class="st"> </span>10L
batch_size    &lt;-<span class="st"> </span>100L
epochs        &lt;-<span class="st"> </span><span class="dv">5</span></code></pre></div>
</div>
<div id="build-the-model" class="section level2">
<h2>Build the model</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">build_model &lt;-<span class="st"> </span><span class="cf">function</span>(input_dim, output_dim) {
    <span class="co"># We don't need the softmax layer here since CrossEntropyLoss already</span>
    <span class="co"># uses it internally.</span>
    model &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Sequential</span>()
    model<span class="op">$</span><span class="kw">add_module</span>(<span class="st">&quot;linear&quot;</span>,
                     torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">Linear</span>(input_dim, output_dim, <span class="dt">bias =</span> <span class="ot">FALSE</span>))
    <span class="kw">return</span>(model)
}

train &lt;-<span class="st"> </span><span class="cf">function</span>(model, loss, optimizer, x, y) {
    x =<span class="st"> </span><span class="kw">Variable</span>(x, <span class="dt">requires_grad =</span> <span class="ot">FALSE</span>)
    y =<span class="st"> </span><span class="kw">Variable</span>(y, <span class="dt">requires_grad =</span> <span class="ot">FALSE</span>)
    
    <span class="co"># reset gradient</span>
    optimizer<span class="op">$</span><span class="kw">zero_grad</span>()
    
    <span class="co"># forward</span>
    fx     &lt;-<span class="st"> </span>model<span class="op">$</span><span class="kw">forward</span>(x)
    output &lt;-<span class="st"> </span>loss<span class="op">$</span><span class="kw">forward</span>(fx, y)
    
    <span class="co"># backward</span>
    output<span class="op">$</span><span class="kw">backward</span>()
    
    <span class="co"># update parameters</span>
    optimizer<span class="op">$</span><span class="kw">step</span>()
    
    <span class="kw">return</span>(output<span class="op">$</span>data<span class="op">$</span><span class="kw">index</span>(0L))
}

predict &lt;-<span class="st"> </span><span class="cf">function</span>(model, x) {
    xvar &lt;-<span class="st">  </span><span class="kw">Variable</span>(x, <span class="dt">requires_grad =</span> <span class="ot">FALSE</span>)
    output =<span class="st"> </span>model<span class="op">$</span><span class="kw">forward</span>(xvar)
    <span class="kw">return</span>(np<span class="op">$</span><span class="kw">argmax</span>(output<span class="op">$</span>data, <span class="dt">axis =</span> 1L))
}

batching &lt;-<span class="st"> </span><span class="cf">function</span>(k) {
    k &lt;-<span class="st"> </span>k <span class="op">-</span><span class="st"> </span><span class="dv">1</span>                             <span class="co"># index in Python start at [0]</span>
    start &lt;-<span class="st"> </span><span class="kw">as.integer</span>(k <span class="op">*</span><span class="st"> </span>batch_size)
    end   &lt;-<span class="st"> </span><span class="kw">as.integer</span>((k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>batch_size)
    
    cost  &lt;-<span class="st"> </span><span class="kw">train</span>(model, loss, optimizer,
                       trX<span class="op">$</span><span class="kw">narrow</span>(0L, start, end<span class="op">-</span>start),
                       trY<span class="op">$</span><span class="kw">narrow</span>(0L, start, end<span class="op">-</span>start))
    
    <span class="co"># allow ccost to accumulate. beware of the &lt;&lt;-</span>
    ccost &lt;&lt;-<span class="st"> </span>ccost <span class="op">+</span><span class="st"> </span>cost<span class="op">$</span><span class="kw">numpy</span>()   <span class="co"># because we don't have yet `+` func</span>
    <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">model =</span> model, <span class="dt">cost =</span> ccost))
}


model     &lt;-<span class="st"> </span><span class="kw">build_model</span>(n_features, n_classes)
loss      &lt;-<span class="st"> </span>torch<span class="op">$</span>nn<span class="op">$</span><span class="kw">CrossEntropyLoss</span>(<span class="dt">size_average =</span> <span class="ot">TRUE</span>)
optimizer &lt;-<span class="st"> </span>optim<span class="op">$</span><span class="kw">SGD</span>(model<span class="op">$</span><span class="kw">parameters</span>(), <span class="dt">lr =</span> learning_rate, <span class="dt">momentum =</span> momentum)</code></pre></div>
</div>
<div id="perform-optimization" class="section level2">
<h2>Perform optimization</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># loop through epochs</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq</span>(<span class="dv">1</span>, epochs)) {
    ccost &lt;-<span class="st"> </span><span class="fl">0.0</span>
    num_batches &lt;-<span class="st"> </span>n_examples <span class="op">%/%</span><span class="st"> </span>batch_size
    
    <span class="co"># using lapply for the batch</span>
    batch_li &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="kw">seq</span>(<span class="dv">1</span>, num_batches), batching)[[num_batches]]
    ccost    &lt;-<span class="st"> </span>batch_li<span class="op">$</span>cost
    predY    &lt;-<span class="st"> </span><span class="kw">predict</span>(batch_li<span class="op">$</span>model, teX)
    <span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">&quot;Epoch = %3d, cost = %f, acc = %.2f%% </span><span class="ch">\n</span><span class="st">&quot;</span>,
              i, ccost <span class="op">/</span><span class="st"> </span>num_batches, <span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(predY<span class="op">$</span><span class="kw">numpy</span>() <span class="op">==</span><span class="st"> </span>teY<span class="op">$</span><span class="kw">numpy</span>())))
}
<span class="co">#&gt; Epoch =   1, cost = 0.547787, acc = 90.15% </span>
<span class="co">#&gt; Epoch =   2, cost = 0.365290, acc = 90.95% </span>
<span class="co">#&gt; Epoch =   3, cost = 0.338373, acc = 91.26% </span>
<span class="co">#&gt; Epoch =   4, cost = 0.324327, acc = 91.48% </span>
<span class="co">#&gt; Epoch =   5, cost = 0.315265, acc = 91.73%</span>

<span class="co"># Epochs</span>
<span class="co">#    5    Epoch =   1, cost = 0.547787, acc = 90.15% </span>
<span class="co">#    5    Epoch =   5, cost = 0.315265, acc = 91.73%</span>
<span class="co">#   50    Epoch =   1, cost = 0.547787, acc = 90.15% </span>
<span class="co">#   50    Epoch =  50, cost = 0.261484, acc = 92.42% </span></code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
